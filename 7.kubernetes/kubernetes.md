# Kubernetes

**Cluster**
![alt text](attachments/cluster.jpeg)
- Cluster = l‚Äôintero datacenter Kubernetes
- Cos‚Äô√® il cluster EKS:  composto da Control plane + Worker nodes

*Control plane:* API server, scheduler, controller manager, etcd. In EKS √® gestito da AWS. Non c‚Äô√® un tuo ‚Äúmaster node‚Äù su EC2.

*Worker nodes:* le istanze dove girano i Pod. Sono EC2 (providerID AWS), pronte, v1.33.4-eks-‚Ä¶

- Comando utile: kubectl get nodes -o wide

**Namespace**
- Namespace = ‚Äústanze‚Äù dentro quel datacenter. Pi√π namespace convivono nello stesso cluster.

L‚Äôisolamento √® solo logico: per isolare rete serve NetworkPolicy.

Quote/limiti si applicano a livello di namespace, non di cluster.

Cos‚Äô√® un namespace

Partizione logica dentro un singolo cluster.

Contiene risorse ‚Äúnamespaced‚Äù (Pod, Service, Deployment, ConfigMap, Secret, ‚Ä¶).

Non contiene risorse ‚Äúcluster-scoped‚Äù (Node, PersistentVolume, ClusterRole, CRD, ‚Ä¶).

Serve per isolamento logico, quote/limiti, RBAC e naming.

Comandi tipici:

kubectl get ns

kubectl get pods -n <ns>

kubectl get all -n <ns>

**Deployment**
![alt text](attachments/deployaml.jpeg)

**Service**
![alt text](attachments/serviceyaml.jpeg)


**Worker Node**

in EKS un worker node tipicamente corrisponde a una istanza EC2.
- Ogni EC2 registrata al cluster = 1 nodo Kubernetes.
- I nodi stanno in node group (ASG o managed node groups).
- Alternative: con Fargate non gestisci EC2; i Pod girano su infrastruttura gestita e non amministri nodi.

Note utili:
- Un nodo pu√≤ eseguire pi√π Pod. Il limite dipende da vCPU/RAM e dai limiti Pod-per-nodo dell‚Äôistanza.
- Control plane EKS √® separato e gestito da AWS, non √® nelle tue EC2.

 



 



**Kubectl**




**multi-tenancy**
Condivisione di risorse: Invece che avere un'infrastruttura separata per ogni cliente, diversi tenant utilizzano la stessa istanza software, lo stesso sistema operativo e la stessa infrastruttura hardware sottostante





# ** üß† CPU vs Memoria in Kubernetes ‚Äî spiegato facile **
Tipo risorsa	A cosa serve	Se sbagli cosa succede
CPU	Quante istruzioni pu√≤ eseguire il container nel tempo ‚Üí calcolo	Se √® troppo poca: il pod viene rallentato (throttling), ma NON crasha
Memoria	Quanta RAM pu√≤ usare per dati in uso, heap, cache ecc.	Se √® troppa poca: il pod va in crash (OOMKilled)

üß† Trucco per ricordare (con analogia semplice):
Immagina un cuoco (container) che cucina in una cucina (pod):

üîπ CPU = mani del cuoco

Pi√π mani ha ‚Üí pi√π pu√≤ lavorare in parallelo. Se ha solo 1 mano ‚Üí lavora lentamente (throttling), ma non muore.

üîπ Memoria = tavolo da lavoro (RAM)

Se il tavolo √® troppo piccolo e non ci sta la roba ‚Üí il piatto cade per terra ‚Üí crash (OOMKilled).



CONSUMI RISORSE KUBE

Verifica richieste/limiti dichiarati nei Pod

kubectl get pod -n prov-ippv2-svts-platform-namespace -o=custom-columns='NAME:.metadata.name,CPU_REQUEST:.spec.containers[*].resources.requests.cpu,CPU_LIMIT:.spec.containers[*].resources.limits.cpu,MEM_REQUEST:.spec.containers[*].resources.requests.memory,MEM_LIMIT:.spec.containers[*].resources.limits.memory'



Oppure un esempio pi√π leggibile (usa kubectl describe):

kubectl describe pod <POD_NAME> -n <NAMESPACE>




Passaggio successivo: verifica utilizzo effettivo
kubectl top pod -n prov-ippv2-svts-platform-namespace
