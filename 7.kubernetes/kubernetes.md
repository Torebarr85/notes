# Kubernetes

**Cluster**
![alt text](attachments/cluster.jpeg)
- Cluster = l‚Äôintero datacenter Kubernetes
- Cos‚Äô√® il cluster EKS:  composto da Control plane + Worker nodes

*Control plane:* API server, scheduler, controller manager, etcd. In EKS √® gestito da AWS. Non c‚Äô√® un tuo ‚Äúmaster node‚Äù su EC2.

*Worker nodes:* le istanze dove girano i Pod. Sono EC2 (providerID AWS), pronte, v1.33.4-eks-‚Ä¶

- Comando utile: kubectl get nodes -o wide

**Namespace**
- Namespace = ‚Äústanze‚Äù dentro quel datacenter. Pi√π namespace convivono nello stesso cluster.

L‚Äôisolamento √® solo logico: per isolare rete serve NetworkPolicy.

Quote/limiti si applicano a livello di namespace, non di cluster.

Cos‚Äô√® un namespace

Partizione logica dentro un singolo cluster.

Contiene risorse ‚Äúnamespaced‚Äù (Pod, Service, Deployment, ConfigMap, Secret, ‚Ä¶).

Non contiene risorse ‚Äúcluster-scoped‚Äù (Node, PersistentVolume, ClusterRole, CRD, ‚Ä¶).

Serve per isolamento logico, quote/limiti, RBAC e naming.

Comandi tipici:

kubectl get ns

kubectl get pods -n <ns>

kubectl get all -n <ns>

**Deployment**
![alt text](attachments/deployaml.jpeg)

**Service**
![alt text](attachments/serviceyaml.jpeg)


**Worker Node**

in EKS un worker node tipicamente corrisponde a una istanza EC2.
- Ogni EC2 registrata al cluster = 1 nodo Kubernetes.
- I nodi stanno in node group (ASG o managed node groups).
- Alternative: con Fargate non gestisci EC2; i Pod girano su infrastruttura gestita e non amministri nodi.

Note utili:
- Un nodo pu√≤ eseguire pi√π Pod. Il limite dipende da vCPU/RAM e dai limiti Pod-per-nodo dell‚Äôistanza.
- Control plane EKS √® separato e gestito da AWS, non √® nelle tue EC2.

 



 



**Kubectl**




**multi-tenancy**
Condivisione di risorse: Invece che avere un'infrastruttura separata per ogni cliente, diversi tenant utilizzano la stessa istanza software, lo stesso sistema operativo e la stessa infrastruttura hardware sottostante





# ** üß† CPU vs Memoria in Kubernetes ‚Äî spiegato facile **
Tipo risorsa	A cosa serve	Se sbagli cosa succede
CPU	Quante istruzioni pu√≤ eseguire il container nel tempo ‚Üí calcolo	Se √® troppo poca: il pod viene rallentato (throttling), ma NON crasha
Memoria	Quanta RAM pu√≤ usare per dati in uso, heap, cache ecc.	Se √® troppa poca: il pod va in crash (OOMKilled)

üß† Trucco per ricordare (con analogia semplice):
Immagina un cuoco (container) che cucina in una cucina (pod):

üîπ CPU = mani del cuoco

Pi√π mani ha ‚Üí pi√π pu√≤ lavorare in parallelo. Se ha solo 1 mano ‚Üí lavora lentamente (throttling), ma non muore.

üîπ Memoria = tavolo da lavoro (RAM)

Se il tavolo √® troppo piccolo e non ci sta la roba ‚Üí il piatto cade per terra ‚Üí crash (OOMKilled).



CONSUMI RISORSE KUBE

Verifica richieste/limiti dichiarati nei Pod

kubectl get pod -n prov-ippv2-svts-platform-namespace -o=custom-columns='NAME:.metadata.name,CPU_REQUEST:.spec.containers[*].resources.requests.cpu,CPU_LIMIT:.spec.containers[*].resources.limits.cpu,MEM_REQUEST:.spec.containers[*].resources.requests.memory,MEM_LIMIT:.spec.containers[*].resources.limits.memory'



Oppure un esempio pi√π leggibile (usa kubectl describe):

kubectl describe pod <POD_NAME> -n <NAMESPACE>





**üß† STEP 1: Capire cosa stai guardando**

Questa tabella mostra:

Campo	Cosa significa
NAME	Il nome del pod
CPU_REQUEST	CPU minima garantita dal cluster
CPU_LIMIT	CPU massima che il pod pu√≤ usare
MEM_REQUEST	RAM minima garantita
MEM_LIMIT	RAM massima prima di essere OOMKilled (crash)

‚úÖ Se il pod consuma meno di request ‚Üí tutto ok.
‚ö†Ô∏è Se consuma pi√π della request ma meno del limite ‚Üí rischi throttling o crash in caso di picchi.
üî• Se consuma pi√π del limite ‚Üí crash immediato (OOM per RAM, throttling per CPU).



**kubectl top pod -n prov-ippv2-svts-platform-namespace**

üß™ A cosa servono requests e limits?
Campo	        Significato	                                Esempio
requests.cpu	Quanta CPU viene prenotata per il container	Garantisce che il container abbia almeno questa quantit√†
limits.cpu	    Quanta CPU pu√≤ usare al massimo	            Se la supera ‚Üí throttling
requests.memory	Quanta RAM prenotata	                    Il scheduler cerca un nodo con questa RAM
limits.memory	Quanta RAM pu√≤ usare al massimo	            Se la supera ‚Üí OOMKilled üí•



Ottima domanda. Fermiamoci a **capire bene come si leggono questi dati**, cos√¨ la prossima volta potrai **fare le analisi in autonomia**, esattamente come ho fatto per SVTS e CL.

Ti insegno passo per passo **come leggere questi dati** e valutare quando c‚Äô√® **spreco, rischio o tutto va bene**.

---

## üß† STEP 1: Capire cosa stai guardando

Questa tabella mostra:

| Campo         | Cosa significa                                |
| ------------- | --------------------------------------------- |
| `NAME`        | Il nome del pod                               |
| `CPU_REQUEST` | CPU minima garantita dal cluster              |
| `CPU_LIMIT`   | CPU massima che il pod pu√≤ usare              |
| `MEM_REQUEST` | RAM minima garantita                          |
| `MEM_LIMIT`   | RAM massima prima di essere OOMKilled (crash) |

> ‚úÖ Se il pod **consuma meno di request** ‚Üí tutto ok.
> ‚ö†Ô∏è Se **consuma pi√π della request ma meno del limite** ‚Üí rischi throttling o crash in caso di picchi.
> üî• Se **consuma pi√π del limite** ‚Üí crash immediato (OOM per RAM, throttling per CPU).

---

## üß™ STEP 2: Cerca i valori **anomali o sbilanciati**

Ecco cosa cerchi **a colpo d‚Äôocchio**:

### üü° Pattern 1: CPU richiesta molto pi√π alta di quanto serve

* Se un pod ha `CPU_REQUEST=400m` ma **consuma 5m**, sta **sprecando risorse prenotate**.

### üî¥ Pattern 2: `MEM_REQUEST` o `MEM_LIMIT` in formato errato

* Come `256M` invece di `256Mi` ‚Üí Kubernetes potrebbe **non capirlo bene**, comportamento imprevedibile.

### üî• Pattern 3: RAM limite altissima senza motivo

* Se `LIMIT=4Gi` ma `USE=500Mi` ‚Üí stai riservando **RAM che nessuno usa**, ma che nessun altro pod pu√≤ toccare.

### ‚ö†Ô∏è Pattern 4: MEM uso vicino al limite

* Se `MEM_USE ‚âà MEM_LIMIT`, sei **a rischio crash** per picchi minimi.

---

## üëÅÔ∏è STEP 3: Confronta coppie di valori

Fai questo:

| Cosa guardi                | Cosa significa                                                    |
| -------------------------- | ----------------------------------------------------------------- |
| `CPU_REQUEST vs CPU_LIMIT` | Quanto √® elastico il pod? Se troppo vicino, pu√≤ subire throttling |
| `CPU_REQUEST vs USO`       | Se uso √® molto basso ‚Üí stai prenotando troppa CPU                 |
| `MEM_REQUEST vs MEM_USE`   | Se uso > request ‚Üí potresti andare in OOM se i nodi sono stretti  |
| `MEM_LIMIT vs MEM_USE`     | Se uso << limite ‚Üí puoi abbassare limite                          |

---

## üß∞ Esempio pratico: analizziamo una riga

```
prov-ippv2-pr-platform-ippv2-backend-7747c84bc5-2w6sw
CPU_REQUEST=400m
CPU_LIMIT=2
MEM_REQUEST=2Gi
MEM_LIMIT=4Gi
```

**Domande da porti:**

1. ‚öôÔ∏è **CPU**

   * 400m √® 0.4 core garantiti ‚Üí bene se backend fa lavoro intenso.
   * Limite a 2 core ‚Üí elastico.
   * **Se uso reale √® basso (es. 5m)** ‚Üí stai **prenotando risorse inutili**.

2. üß† **Memoria**

   * 2Gi richiesti ‚Üí schedulazione solo su nodi con molta RAM.
   * 4Gi limite ‚Üí se non li usa, stai buttando RAM.
   * Se uso √® tipo **200Mi**, hai 10x di spreco.

---

## üìå STEP 4: Riconosci i contesti

L‚Äôambiente `prod` √® diverso da `dev` o `collaudo`:

| Ambiente     | Obiettivo       | Strategia                                 |
| ------------ | --------------- | ----------------------------------------- |
| **dev**      | fare test       | tutto minimo, anche se crasha             |
| **collaudo** | test realistici | risorse ridotte ma coerenti               |
| **prod**     | stabilit√†       | richieste **accurate**, limiti ben tarati |

Quindi in **PROD**:

* **Requests vanno tarati bene** (non troppo bassi)
* **Limiti vanno bilanciati**: n√© troppo stretti, n√© 10x inutili
* I pod non devono essere "overkill", altrimenti saturano il cluster

---

## üß† TRUCCHETTO VISIVO

Per ogni riga della tabella, **pensa in questi 3 livelli:**

```
[ MEM USE ] < [ MEM REQUEST ] < [ MEM LIMIT ]
     OK          OK (schedulabile)    OK (non crasha)

Se invece:
[ MEM USE ] > [ MEM REQUEST ] ‚Üí pu√≤ andare in OOM se non ha risorse libere nel nodo
[ MEM USE ] ‚âà [ MEM LIMIT ] ‚Üí rischia crash!
```

---

## üîö Ricapitolando: Come leggere la tabella

| Cosa cerchi          | Azione                                |
| -------------------- | ------------------------------------- |
| `CPU_REQUEST >> uso` | Abbassa la request                    |
| `MEM_LIMIT >> uso`   | Abbassa il limite                     |
| `MEM_REQUEST < uso`  | Alza la request                       |
| `Formato = 256M`     | Correggi ‚Üí `256Mi`                    |
| `kestra = 4Gi`       | Da valutare: se uso √® < 1Gi, √® troppo |

---

‚úÖ Appena mi dai anche `kubectl top pod -n prov-ippv2-pr-platform-namespace`, ti faccio l‚Äôanalisi completa in stile SVTS e CL, **ma ora potrai anche capirla da solo leggendo i dati come sopra**.

Vuoi procedere?
